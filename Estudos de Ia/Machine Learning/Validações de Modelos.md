## **1Ô∏è‚É£ Divis√£o do Conjunto de Dados (supervisionado)**

### Conceito:

- Em problemas **supervisionados**, o modelo aprende com dados que possuem **entrada (features) e sa√≠da (r√≥tulo/target)**.
    
- Para avaliar corretamente o desempenho, os dados precisam ser **divididos** em conjuntos diferentes:
    
    1. **Treino (Training Set)** ‚Üí usado para treinar o modelo.
        
    2. **Valida√ß√£o (Validation Set)** ‚Üí usado para ajustar hiperpar√¢metros e evitar overfitting.
        
    3. **Teste (Test Set)** ‚Üí usado para avaliar a performance final em dados **n√£o vistos**.
        

### M√©todos de divis√£o:

- **Hold-Out:** divis√£o simples (ex.: 70% treino, 15% valida√ß√£o, 15% teste).
    
- **K-Fold Cross-Validation:** dados divididos em K partes, cada parte serve de teste em uma rodada.
    
- **Stratified K-Fold:** mesma ideia do K-Fold, mas mant√©m propor√ß√£o das classes para evitar desbalanceamento.
    

üí° **Dica:** Para problemas de classifica√ß√£o com classes desbalanceadas, sempre prefira **Stratified K-Fold**.

---

## **2Ô∏è‚É£ M√©tricas de Desempenho**

### Conceito:

- Avaliam **o qu√£o bem o modelo aprendeu os padr√µes dos dados**.
    
- Dependem do tipo de problema:
    
    - **Classifica√ß√£o:** acur√°cia, precis√£o, recall, F1-score, AUC-ROC.
        
    - **Regress√£o:** RMSE, MAE, R¬≤.
        

### Import√¢ncia:

- Permitem comparar modelos e escolher aquele que **melhor generaliza**.
    
- S√£o m√©tricas t√©cnicas, ligadas diretamente √† performance estat√≠stica do modelo.
    

---

## **3Ô∏è‚É£ M√©tricas de Neg√≥cio**

### Conceito:

- Avaliam **o impacto do modelo na realidade do neg√≥cio**, ou seja, se o modelo realmente traz **valor**.
    
- Exemplo:
    
    - Reduzir churn de clientes em X%.
        
    - Aumentar convers√£o de vendas em Y%.
        
    - Minimizar custo de falsos positivos ou falsos negativos.
        

### Import√¢ncia:

- Um modelo pode ter √≥tima acur√°cia, mas **n√£o gerar valor real** para o neg√≥cio.
    
- Essas m√©tricas ajudam a **alinhar o modelo com objetivos estrat√©gicos**.
    

---

## **4Ô∏è‚É£ Quest√µes N√£o Funcionais**

### Conceito:

- Avaliam caracter√≠sticas **operacionais ou de qualidade** do modelo, n√£o diretamente relacionadas √† acur√°cia.
    
- Exemplos:
    
    - **Performance:** tempo de infer√™ncia, capacidade de processar grandes volumes de dados.
        
    - **Robustez:** resist√™ncia a ru√≠do ou dados incompletos.
        
    - **Manutenibilidade:** facilidade de atualiza√ß√£o e manuten√ß√£o do modelo.
        
    - **Explicabilidade:** transpar√™ncia e capacidade de explicar decis√µes (importante para setores regulados).
        

### Import√¢ncia:

- Garantem que o modelo seja **eficiente, confi√°vel e utiliz√°vel** em produ√ß√£o, al√©m de apenas preciso.
    

---

## **üìå Resumo Integrado**

|Requisito|O que avalia|Exemplos / Observa√ß√µes|
|---|---|---|
|Divis√£o de dados|Avalia generaliza√ß√£o|Hold-out, K-Fold, Stratified K-Fold|
|M√©tricas de desempenho|Avalia aprendizado do modelo|Acur√°cia, F1-score, RMSE, R¬≤|
|M√©tricas de neg√≥cio|Avalia valor real|Redu√ß√£o de churn, aumento de vendas, ROI|
|Quest√µes n√£o funcionais|Avalia opera√ß√£o e qualidade|Tempo de infer√™ncia, robustez, explicabilidade|

üí° **Dica pr√°tica:**  
Um bom processo de valida√ß√£o **combina todos esses requisitos**:

- Divide os dados corretamente,
    
- Mede o desempenho t√©cnico,
    
- Verifica impacto real no neg√≥cio,
    
- E garante que o modelo funcione bem em produ√ß√£o.
    

---

# Valida√ß√µes dos Modelos de treino

## [[Hold-Out]]
---
## [[K-Fold Cross-Validation]]
---
## [[Stratified K-Fold Cross-Validation]]
---
### üí° Resumo Comparativo

|M√©todo|Quando usar|Vantagens|Desvantagens|
|---|---|---|---|
|**Hold-Out**|Dados grandes e simples|R√°pido, f√°cil de implementar|Alta variabilidade na avalia√ß√£o|
|**K-Fold**|Dados pequenos ou m√©dios|Avalia√ß√£o robusta|Mais lento, n√£o garante balanceamento de classes|
|**Stratified K-Fold**|Classifica√ß√£o com classes desbalanceadas|Avalia√ß√£o robusta e balanceada|Mais lento e mais complexo|
